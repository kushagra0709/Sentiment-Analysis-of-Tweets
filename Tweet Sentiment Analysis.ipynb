{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "X7GK2w9XjNEY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "working_directory=os.getcwd()\n",
    "path=working_directory+'/downloads/Tweets.csv'\n",
    "df1 = pd.read_csv(path)\n",
    "#getting rid of null values\n",
    "df1 = df1.dropna()\n",
    "#Adding the sentiments column\n",
    "df1['sentiments'] = df1.sentiment.apply(lambda x: 0 if x in ['negative', 'neutral'] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CMYTiSo2jsE6"
   },
   "outputs": [],
   "source": [
    "X = df1['selected_text']\n",
    "y = df1['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7e5j7Y7j6Y7",
    "outputId": "8fc7b366-dc5d-4424-a417-b53b670bc2c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression with CountVectorizer\n",
      "0.9069868995633188\n",
      "9041 366 912 3421\n",
      "0.7895 0.9611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.5, random_state=24)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "#Vectorizing the text data\n",
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Training the model\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(ctmTr, y_train)\n",
    "#Accuracy score\n",
    "lr_score = lr.score(X_test_dtm, y_test)\n",
    "print(\"Results for Logistic Regression with CountVectorizer\")\n",
    "print(lr_score)\n",
    "#Predicting the labels for test data\n",
    "y_pred_lr = lr.predict(X_test_dtm)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#Confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "#True positive and true negative rates\n",
    "tpr_lr = round(tp/(tp + fn), 4)\n",
    "tnr_lr = round(tn/(tn+fp), 4)\n",
    "print(tpr_lr, tnr_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuLB9s5Uj9C2",
    "outputId": "9c7430bc-1895-4be0-a4ea-be4995e0e3c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Support Vector Machine with CountVectorizer\n",
      "0.898471615720524\n",
      "9299 171 1224 3046\n",
      "0.7133 0.9819\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=123)\n",
    "#Vectorizing the text data\n",
    "cv = CountVectorizer()\n",
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)\n",
    "from sklearn import svm\n",
    "#Training the model\n",
    "svcl = svm.SVC(gamma='scale')\n",
    "svcl.fit(ctmTr, y_train)\n",
    "svcl_score = svcl.score(X_test_dtm, y_test)\n",
    "print(\"Results for Support Vector Machine with CountVectorizer\")\n",
    "print(svcl_score)\n",
    "y_pred_sv = svcl.predict(X_test_dtm)\n",
    "#Confusion matrix\n",
    "cm_sv = confusion_matrix(y_test, y_pred_sv)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_sv).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_sv = round(tp/(tp + fn), 4)\n",
    "tnr_sv = round(tn/(tn+fp), 4)\n",
    "print(tpr_sv, tnr_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GflVRBGzkUZl",
    "outputId": "e346f321-430e-4740-ddd3-3c3107cf11fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNN Classifier with CountVectorizer\n",
      "0.8152110625909752\n",
      "7906 1488 1051 3295\n",
      "0.7582 0.8416\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=143)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "ctmTr = cv.fit_transform(X_train)\n",
    "X_test_dtm = cv.transform(X_test)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(ctmTr, y_train)\n",
    "knn_score = knn.score(X_test_dtm, y_test)\n",
    "print(\"Results for KNN Classifier with CountVectorizer\")\n",
    "print(knn_score)\n",
    "y_pred_knn = knn.predict(X_test_dtm)\n",
    "#Confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_knn = round(tp/(tp + fn), 4)\n",
    "tnr_knn = round(tn/(tn+fp), 4)\n",
    "print(tpr_knn, tnr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9LCrZfgkWu_",
    "outputId": "4f632cb9-ccb6-4f25-a2f7-1765a138a9c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression with tfidf\n",
      "0.900509461426492\n",
      "9234 173 1194 3139\n",
      "0.7244 0.9816\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=45)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train_vec, y_train)\n",
    "lr_score = lr.score(X_test_vec, y_test)\n",
    "print(\"Results for Logistic Regression with tfidf\")\n",
    "print(lr_score)\n",
    "y_pred_lr = lr.predict(X_test_vec)\n",
    "#Confusion matrix\n",
    "\n",
    "cm_knn = confusion_matrix(y_test, y_pred_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_knn = round(tp/(tp + fn), 4)\n",
    "tnr_knn = round(tn/(tn+fp), 4)\n",
    "print(tpr_knn, tnr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "we_J-l2al-EQ",
    "outputId": "e5525341-5281-48f7-ff3c-38d7a5125b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Support Vector Machine with tfidf\n",
      "0.911863173216885\n",
      "9261 174 1037 3268\n",
      "0.7591 0.9816\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=55)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "svcl = svm.SVC(kernel = 'rbf',gamma='scale')\n",
    "\n",
    "svcl.fit(X_train_vec, y_train)\n",
    "svcl_score = svcl.score(X_test_vec, y_test)\n",
    "print(\"Results for Support Vector Machine with tfidf\")\n",
    "print(svcl_score)\n",
    "y_pred_sv = svcl.predict(X_test_vec)\n",
    "#Confusion matrix\n",
    "\n",
    "cm_sv = confusion_matrix(y_test, y_pred_sv)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_sv).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_sv = round(tp/(tp + fn), 4)\n",
    "tnr_sv = round(tn/(tn+fp), 4)\n",
    "print(tpr_sv, tnr_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNkDTNzSmEyy",
    "outputId": "99b8ab43-ccd6-4c68-e63c-6129e85044ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNN Classifier with tfidf\n",
      "0.8709606986899563\n",
      "9100 306 1467 2867\n",
      "0.6615 0.9675\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=65)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_vec, y_train)\n",
    "knn_score = knn.score(X_test_vec, y_test)\n",
    "print(\"Results for KNN Classifier with tfidf\")\n",
    "print(knn_score)\n",
    "y_pred_knn = knn.predict(X_test_vec)\n",
    "#Confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_knn = round(tp/(tp + fn), 4)\n",
    "tnr_knn = round(tn/(tn+fp), 4)\n",
    "print(tpr_knn, tnr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WQ5zWqV5mIFx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression with Hash Vectorizer\n",
      "0.8962154294032023\n",
      "9214 193 1233 3100\n",
      "0.7154 0.3295\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=45)\n",
    "hash_vectorizer=HashingVectorizer()\n",
    "X_hashtrain_vec=hash_vectorizer.fit_transform(X_train)\n",
    "X_hashtest_vec=hash_vectorizer.transform(X_test)\n",
    "\n",
    "lr=LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_hashtrain_vec,y_train)\n",
    "lr_score=lr.score(X_hashtest_vec,y_test)\n",
    "print(\"Results for Logistic Regression with Hash Vectorizer\")\n",
    "print(lr_score)\n",
    "y_pred_lr=lr.predict(X_hashtest_vec)\n",
    "#Confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "tn,fp,fn,tp=confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "tpr_lr=round(tp/(tp+fn),4)\n",
    "tnr_lr=round(tp/(tn+fp),4)\n",
    "print(tpr_lr,tnr_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Support Vector Machine with Hash Vectorizer\n",
      "0.911863173216885\n",
      "9284 151 1095 3210\n",
      "0.7456 0.984\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=55)\n",
    "hash_vectorizer=HashingVectorizer()\n",
    "X_hashtrain_vec=hash_vectorizer.fit_transform(X_train)\n",
    "X_hashtest_vec=hash_vectorizer.transform(X_test)\n",
    "\n",
    "svc1=svm.SVC(gamma='scale')\n",
    "svc1.fit(X_hashtrain_vec,y_train)\n",
    "svc1_score=svc1.score(X_hashtest_vec,y_test)\n",
    "print(\"Results for Support Vector Machine with Hash Vectorizer\")\n",
    "print(svcl_score)\n",
    "y_pred_sv=svc1.predict(X_hashtest_vec)\n",
    "#Confusion matrix\n",
    "cm_sv = confusion_matrix(y_test, y_pred_sv)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_sv).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_sv = round(tp/(tp + fn), 4)\n",
    "tnr_sv = round(tn/(tn+fp), 4)\n",
    "print(tpr_sv, tnr_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for KNN Classifier with Hash Vectorizer\n",
      "0.8812954876273653\n",
      "9159 247 1384 2950\n",
      "0.6807 0.9737\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.5, random_state=65)\n",
    "hash_vectorizer=HashingVectorizer()\n",
    "X_hashtrain_vec=hash_vectorizer.fit_transform(X_train)\n",
    "X_hashtest_vec=hash_vectorizer.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_hashtrain_vec, y_train)\n",
    "knn_score = knn.score(X_hashtest_vec, y_test)\n",
    "print(\"Results for KNN Classifier with Hash Vectorizer\")\n",
    "print(knn_score)\n",
    "y_pred_knn = knn.predict(X_hashtest_vec)\n",
    "#Confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_knn).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "tpr_knn = round(tp/(tp + fn), 4)\n",
    "tnr_knn = round(tn/(tn+fp), 4)\n",
    "print(tpr_knn, tnr_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
